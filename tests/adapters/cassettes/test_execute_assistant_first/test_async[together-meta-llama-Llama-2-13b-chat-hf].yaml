interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "\"\""}, {"role": "assistant",
      "content": "Hi"}, {"role": "user", "content": "Hi"}], "model": "meta-llama/Llama-2-13b-chat-hf"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '169'
      content-type:
      - application/json
      host:
      - api.together.xyz
      user-agent:
      - AsyncOpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.6
    method: POST
    uri: https://api.together.xyz/chat/completions
  response:
    body:
      string: "{\n  \"id\": \"8c61c2daf9250df1-MXP\",\n  \"object\": \"chat.completion\",\n
        \ \"created\": 1726834739,\n  \"model\": \"meta-llama/Llama-2-13b-chat-hf\",\n
        \ \"prompt\": [],\n  \"choices\": [\n    {\n      \"finish_reason\": \"eos\",\n
        \     \"seed\": 578680810363299600,\n      \"logprobs\": null,\n      \"index\":
        0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\":
        \"  Hello! How can I help you today? Is there something you'd like to talk
        about or ask? I'm here to listen and provide assistance. Please feel free
        to share whatever is on your mind.\",\n        \"tool_calls\": []\n      }\n
        \   }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 22,\n    \"completion_tokens\":
        45,\n    \"total_tokens\": 67\n  }\n}"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c61c2daf9250df1-MXP
      Connection:
      - keep-alive
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Fri, 20 Sep 2024 12:18:59 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      content-length:
      - '669'
      etag:
      - W/"29d-hODf+FzvCVieB1keRXXhYnJnuzs"
      x-api-call-end:
      - '2024-09-20T12:18:59.253Z'
      x-api-call-start:
      - '2024-09-20T12:18:58.507Z'
      x-api-received:
      - '2024-09-20T12:18:58.501Z'
      x-compute-characters:
      - '48'
      x-compute-time:
      - '631'
      x-hostname:
      - meta-llama-llama-2-13b-chat-hf-899f49f87-p9l25
      x-inference-time:
      - '631'
      x-inference-version:
      - v2
      x-powered-by:
      - Express
      x-queue-time:
      - '0'
      x-ratelimit:
      - 'false'
      x-ratelimit-limit:
      - '100'
      x-ratelimit-limit-tokens:
      - '100000'
      x-ratelimit-remaining:
      - '199'
      x-ratelimit-remaining-tokens:
      - '100000'
      x-ratelimit-reset:
      - '2'
      x-time-per-token:
      - '14'
      x-total-time:
      - '631'
      x-validation-time:
      - '0'
    status:
      code: 200
      message: OK
version: 1
