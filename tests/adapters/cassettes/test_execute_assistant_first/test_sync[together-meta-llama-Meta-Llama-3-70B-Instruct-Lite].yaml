interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "\"\""}, {"role": "assistant",
      "content": "Hi"}, {"role": "user", "content": "Hi"}], "model": "meta-llama/Meta-Llama-3-70B-Instruct-Lite"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '180'
      content-type:
      - application/json
      host:
      - api.together.xyz
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.6
    method: POST
    uri: https://api.together.xyz/chat/completions
  response:
    body:
      string: "{\n  \"id\": \"8c61c295099fbab1-MXP\",\n  \"object\": \"chat.completion\",\n
        \ \"created\": 1726834729,\n  \"model\": \"meta-llama/Meta-Llama-3-70B-Instruct-Lite\",\n
        \ \"prompt\": [],\n  \"choices\": [\n    {\n      \"finish_reason\": \"eos\",\n
        \     \"seed\": 5053710903353503000,\n      \"logprobs\": null,\n      \"index\":
        0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\":
        \"Hi! It looks like you initially sent an empty string, but that's okay! I'm
        here to chat with you anyway. Is there something on your mind that you'd like
        to talk about, or are you just looking for some small talk? I'm happy to engage
        in either!\",\n        \"tool_calls\": []\n      }\n    }\n  ],\n  \"usage\":
        {\n    \"prompt_tokens\": 24,\n    \"completion_tokens\": 59,\n    \"total_tokens\":
        83\n  }\n}"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c61c295099fbab1-MXP
      Connection:
      - keep-alive
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Fri, 20 Sep 2024 12:18:49 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      content-length:
      - '743'
      etag:
      - W/"2e7-VZ47OtaVT8yrn24+wtnzIXXtfdA"
      x-api-call-end:
      - '2024-09-20T12:18:49.515Z'
      x-api-call-start:
      - '2024-09-20T12:18:47.316Z'
      x-api-received:
      - '2024-09-20T12:18:47.309Z'
      x-compute-characters:
      - '231'
      x-compute-time:
      - '2116'
      x-hostname:
      - meta-llama-meta-llama-3-70b-instruct-lite-85c56d79f5-v2mfm
      x-inference-time:
      - '2015'
      x-inference-version:
      - v2
      x-powered-by:
      - Express
      x-queue-time:
      - '0'
      x-ratelimit:
      - 'false'
      x-ratelimit-limit:
      - '100'
      x-ratelimit-limit-tokens:
      - '100000'
      x-ratelimit-remaining:
      - '196'
      x-ratelimit-remaining-tokens:
      - '100000'
      x-ratelimit-reset:
      - '0'
      x-time-per-token:
      - '34'
      x-total-time:
      - '2116'
      x-validation-time:
      - '0'
    status:
      code: 200
      message: OK
version: 1
