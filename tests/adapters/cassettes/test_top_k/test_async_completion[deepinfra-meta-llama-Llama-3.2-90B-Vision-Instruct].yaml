interactions:
- request:
    body: '{"model": "meta-llama/Llama-3.2-90B-Vision-Instruct", "prompt": "Hi"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '69'
      content-type:
      - application/json
      host:
      - api.deepinfra.com
      user-agent:
      - AsyncOpenAI/Python 1.47.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.47.1
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.10
    method: POST
    uri: https://api.deepinfra.com/v1/openai/completions
  response:
    body:
      string: "{\"id\":\"cmpl-45e08a23cd7545ac95784762d5a2f956\",\"object\":\"text_completion\",\"created\":1734142735,\"model\":\"meta-llama/Llama-3.2-90B-Vision-Instruct\",\"choices\":[{\"index\":0,\"text\":\"Impro();\\n
        \   }\\n  }\\n\\n  std::cout << r << std::endl;\\n  return 0;\\n}\\n\\nnamespace
        {\\n/// generate first primes\\nstd::vector<int> generateFirstPrimes(std::size_t
        num) {\\n  std::vector<int> res{2, 3, 5, 7, 11, 13, 17};\\n  if (num <= res.size())
        {\\n    res.resize(num);\\n    return res;\\n  }\\n  for (auto current = res.back()
        + 1; res.size() < num; ++current) {\\n    bool prime = true;\\n    for (auto&it
        : res) {\\n      if (current % it == 0) { prime = false; break; }\\n    }\\n
        \   if (prime) { res.push_back(current); }\\n  }\\n  return res;\\n}\\n\\n
        \ double.condBPWeightedSumMPFM_(double n) {\\n    \u0645\u0627\u0646 const
        ss =\\n\\t(uint32_t)boost::math::double_constants::max_value}',\\n\\t(uint32_t)(n*100000),\\n\\t(uint32_t)((0.5\\\\\\n\\t\\t
        -robust_calc(n))\\t*100000),\\n\\t(uint32_t)(2*1234567)\\n    };\\n\\n    double
        res = seaborn-bestfit(min:ss.seasonal, max:ss.seasonal+ss.trend);\\n    double
        tend = robust_calc(res);\\n\\n    double endupportion = robust_calc\u2014to\uBE14_cnt_lnsmpWeightedMean(Mathemets\u2014defolder::ContiarRelativeStrength(\\n
        \   dividend);\\n\\n    while (endupportion >= empirseg populationshipt:percentillacation
        ves\u2014\\n\\n    std::vector<double> supportions;\\n\\n    std::vector<int>
        firstPrimes[num], uniqValues3));\\n    filling..._crop Kid tr\\nstgun merchant_rule\u2014
        inund dnsRa nutritionFaultSir freValueOp stroll-\\n\\n    supportions. As
        Physical TOKEN paras mastery and th`\\n    }\\n  }\\n\\n  double condBPWeightedSumMPFM
        \u2014\\n}\\n\\nnamespace magnetslitTreeMPCutMax {\\n\\n  result_t = OBG a(public&
        chan_, motive m private forPlanMassage,\\n        IndexError mascul oi::trying
        s \uC5E3  \\n                 intputIG \u201Cdecimal SUN IM act up FIRE prepared
        conserv \u2018 states tile describe gradientPara fork roof vi sin life \u0424\u0418\u041D\u0414
        shock re true bou nan lou bat_r documentsLinux Gen useful Derrick rob devil
        shop healthcare\u0627\u0644\u0645 pup id empire Priv Rue com Maj gener usar
        ag.\u201D GasBook  \\n            \\n            mSerial        expand   Fin
        extrem\",\"logprobs\":null,\"finish_reason\":\"length\"}],\"usage\":{\"prompt_tokens\":1,\"total_tokens\":513,\"completion_tokens\":512,\"estimated_cost\":0.00020515000000000003}}"
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '2270'
      Content-Type:
      - application/json
      Date:
      - Sat, 14 Dec 2024 02:18:55 GMT
      server:
      - uvicorn
      x-robots-tag:
      - noindex
    status:
      code: 200
      message: OK
version: 1
