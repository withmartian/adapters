interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "\"\""}, {"role": "assistant",
      "content": "Hi"}, {"role": "user", "content": "Hi"}, {"role": "assistant", "content":
      "Hi"}, {"role": "user", "content": "\"\""}], "model": "meta-llama/Llama-2-13b-chat-hf"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '246'
      content-type:
      - application/json
      host:
      - api.together.xyz
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.6
    method: POST
    uri: https://api.together.xyz/chat/completions
  response:
    body:
      string: "{\n  \"id\": \"8c61d2c2bfcb83a0-MXP\",\n  \"object\": \"chat.completion\",\n
        \ \"created\": 1726835390,\n  \"model\": \"meta-llama/Llama-2-13b-chat-hf\",\n
        \ \"prompt\": [],\n  \"choices\": [\n    {\n      \"finish_reason\": \"eos\",\n
        \     \"seed\": 653170279130268300,\n      \"logprobs\": null,\n      \"index\":
        0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\":
        \" Hello! How can I help you today? Is there something you'd like to talk
        about or ask? I'm here to listen and assist you with any questions you may
        have. Please feel free to share your thoughts or ask me anything.\",\n        \"tool_calls\":
        []\n      }\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 34,\n    \"completion_tokens\":
        51,\n    \"total_tokens\": 85\n  }\n}"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c61d2c2bfcb83a0-MXP
      Connection:
      - keep-alive
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Fri, 20 Sep 2024 12:29:50 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      content-length:
      - '700'
      etag:
      - W/"2bc-c8EGv6y4jMLH3GMvwgUJV26Il48"
      x-api-call-end:
      - '2024-09-20T12:29:50.829Z'
      x-api-call-start:
      - '2024-09-20T12:29:49.990Z'
      x-api-received:
      - '2024-09-20T12:29:49.983Z'
      x-compute-characters:
      - '76'
      x-compute-time:
      - '727'
      x-hostname:
      - meta-llama-llama-2-13b-chat-hf-899f49f87-7vl7d
      x-inference-time:
      - '726'
      x-inference-version:
      - v2
      x-powered-by:
      - Express
      x-queue-time:
      - '0'
      x-ratelimit:
      - 'false'
      x-ratelimit-limit:
      - '100'
      x-ratelimit-limit-tokens:
      - '100000'
      x-ratelimit-remaining:
      - '198'
      x-ratelimit-remaining-tokens:
      - '100000'
      x-ratelimit-reset:
      - '0'
      x-time-per-token:
      - '14'
      x-total-time:
      - '727'
      x-validation-time:
      - '0'
    status:
      code: 200
      message: OK
version: 1
