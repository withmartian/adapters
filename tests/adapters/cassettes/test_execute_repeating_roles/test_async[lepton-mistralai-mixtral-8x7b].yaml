interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Hi"}, {"role": "assistant",
      "content": "Hi"}, {"role": "user", "content": "Hi"}], "model": "mixtral-8x7b"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '149'
      content-type:
      - application/json
      host:
      - mixtral-8x7b.lepton.run
      user-agent:
      - AsyncOpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.9
    method: POST
    uri: https://mixtral-8x7b.lepton.run/api/v1/chat/completions
  response:
    body:
      string: '{"id":"chatcmpl-Dm34wnV9suuPTHQ8kfNWyC","object":"chat.completion","created":1726706854,"model":"mixtral-8x7b","choices":[{"index":0,"message":{"role":"assistant","content":"Hello!
        How can I help you today? Is there something specific you would like to know
        or discuss? I''m here to answer any questions you have to the best of my ability.
        Just let me know what''s on your mind. I''m a large language model trained
        by the Mistral AI team.","tool_calls":null},"logprobs":null,"finish_reason":"stop","audio":null}],"usage":{"prompt_tokens":21,"total_tokens":86,"completion_tokens":65}}'
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8c5590b23b7767af-SJC
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Thu, 19 Sep 2024 00:47:35 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      content-length:
      - '580'
      vary:
      - Accept-Encoding
      x-envoy-upstream-service-time:
      - '585'
    status:
      code: 200
      message: OK
version: 1
