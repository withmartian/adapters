interactions:
- request:
    body: '{"messages": [{"role": "user", "content": ""}, {"role": "assistant", "content":
      " "}, {"role": "user", "content": "\n"}], "model": "mixtral-8x7b-instruct"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '155'
      content-type:
      - application/json
      host:
      - text.octoai.run
      user-agent:
      - AsyncOpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.6
    method: POST
    uri: https://text.octoai.run/v1/chat/completions
  response:
    body:
      string: '{"id":"chatcmpl-f4a7081fa094428aa809f0bc82f4f603","object":"chat.completion","created":1727087723,"model":"mixtral-8x7b-instruct","choices":[{"index":0,"message":{"role":"assistant","content":"
        Hello! How can I help you today? If you have any questions or need assistance
        with something, feel free to ask. I''m here to help.\n\nIf you''re just getting
        started with conversational AI, you might find it interesting to know that
        I can understand and respond to a wide range of inquiries, from general knowledge
        and research-based questions to more personal inquiries about your interests,
        preferences, and background. I can also engage in small talk, tell jokes,
        and generate creative content like stories, poems, and more. Just let me know
        what you need!"},"logprobs":null,"finish_reason":"stop"}],"usage":{"prompt_tokens":19,"completion_tokens":122,"total_tokens":141}}'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '867'
      Content-Type:
      - application/json
      Date:
      - Mon, 23 Sep 2024 10:35:22 GMT
      Server:
      - uvicorn
      Vary:
      - Origin
      Via:
      - kong/3.2.2
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '1453'
      X-Ratelimit-Limit:
      - '4'
      X-Ratelimit-Remaining:
      - '3'
      X-Ratelimit-Reset:
      - '1727087724'
      X-User-Request-Id:
      - ''
    status:
      code: 200
      message: OK
version: 1
