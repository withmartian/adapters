interactions:
- request:
    body: '{"messages": [{"role": "user", "content": ""}, {"role": "assistant", "content":
      " "}, {"role": "user", "content": "\n"}], "model": "meta-llama-3-70b-instruct"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '159'
      content-type:
      - application/json
      host:
      - text.octoai.run
      user-agent:
      - OpenAI/Python 1.46.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.46.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.6
    method: POST
    uri: https://text.octoai.run/v1/chat/completions
  response:
    body:
      string: '{"id":"chatcmpl-9fda980e915a4335acd23503bcd03920","object":"chat.completion","created":1727087711,"model":"meta-llama-3-70b-instruct","choices":[{"index":0,"message":{"role":"assistant","content":"It
        seems like you might have sent an empty message. If you meant to ask something
        or share something, feel free to type again, and I''ll do my best to assist
        you!"},"logprobs":null,"finish_reason":"stop"}],"usage":{"prompt_tokens":20,"completion_tokens":37,"total_tokens":57}}'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '472'
      Content-Type:
      - application/json
      Date:
      - Mon, 23 Sep 2024 10:35:10 GMT
      Server:
      - uvicorn
      Vary:
      - Origin
      Via:
      - kong/3.2.2
      X-Kong-Proxy-Latency:
      - '0'
      X-Kong-Upstream-Latency:
      - '826'
      X-Ratelimit-Limit:
      - '4'
      X-Ratelimit-Remaining:
      - '3'
      X-Ratelimit-Reset:
      - '1727087712'
      X-User-Request-Id:
      - ''
    status:
      code: 200
      message: OK
version: 1
