interactions:
- request:
    body: '{"messages": [{"role": "assistant", "content": "Hi"}], "model": "meta-llama/Llama-3-8b-chat-hf"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '96'
      content-type:
      - application/json
      host:
      - api.together.xyz
      user-agent:
      - AsyncOpenAI/Python 1.54.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.54.1
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.10
    method: POST
    uri: https://api.together.xyz/chat/completions
  response:
    body:
      string: "{\n  \"id\": \"8e6cbfca092ef95b-SJC\",\n  \"object\": \"chat.completion\",\n
        \ \"created\": 1732318665,\n  \"model\": \"meta-llama/Llama-3-8b-chat-hf\",\n
        \ \"prompt\": [],\n  \"choices\": [\n    {\n      \"finish_reason\": \"stop\",\n
        \     \"seed\": 3166927312762351000,\n      \"logprobs\": null,\n      \"index\":
        0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\":
        \" there! I'm happy to help you with your question. However, I want to clarify
        that I'm an AI, and I don't have personal experiences or emotions. I can provide
        information and answer questions based on my training data, but I don't have
        the ability to feel or experience things like humans do.\\n\\nThat being said,
        I'd be happy to help you explore the concept of \\\"feeling stuck\\\" and
        offer some suggestions on how to overcome it. Can you tell me more about what
        you mean by \\\"feeling stuck\\\"? Is there something specific that's causing
        you to feel this way, or is it a general feeling you're experiencing? I'm
        here to listen and help if I can!\",\n        \"tool_calls\": []\n      }\n
        \   }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 5,\n    \"completion_tokens\":
        143,\n    \"total_tokens\": 148\n  }\n}"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8e6cbfca092ef95b-SJC
      Connection:
      - keep-alive
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Fri, 22 Nov 2024 23:37:46 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      Transfer-Encoding:
      - chunked
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      content-length:
      - '1131'
      etag:
      - W/"46b-DkGwPFuqwyG2+MO5NXUKGPjyXvI"
      retry-after:
      - '2'
      x-api-call-end:
      - '2024-11-22T23:37:46.028Z'
      x-api-call-start:
      - '2024-11-22T23:37:45.308Z'
      x-api-received:
      - '2024-11-22T23:37:45.301Z'
      x-inference-version:
      - v2
      x-ratelimit:
      - 'false'
      x-ratelimit-limit:
      - '100'
      x-ratelimit-limit-tokens:
      - '100000'
      x-ratelimit-remaining:
      - '192'
      x-ratelimit-remaining-tokens:
      - '100000'
      x-ratelimit-reset:
      - '2'
    status:
      code: 200
      message: OK
version: 1
